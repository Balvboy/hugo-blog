---
title: "MySQL问题整理"
date: 2021-12-01T11:07:47+08:00
tags:
    - MySQL
categories: [ MySQL ]
draft: true
---

## InnoDB为什么使用B+树作为索引结构

首先常见的索引结构有

- Hash
- B树[Balance Tree]
- B+树

首先Hash结构，在针对指定索引的查询时，效率最高，为O[1]。
但是MySQL作为一种关系型数据库，经常会有范围查询的需求，这种范围查询对于Hash结构是致命的，如果使用Hash结构进行范围查询，只能通过全表扫描，因为经过Hash之后，即使相邻的数据，也可能分布到相隔很远的数据页中。

所以Hash结构只能淘汰。

B树和B+树有相同点，也有区别

B树
![](/img/btree.png)

B+树
![](/img/b+tree.png)

- 相同点是，他们都是多叉平衡树
- 不同点是
	- B树可以在非叶子节点存储数据
	- B+树，只能在叶子节点存储数据
	- B+数，同一层的节点包括叶子节点之间都是有序的，并且通过链表相连[包括数据页和数据行之间都是相连的]

在查询效率方面，B数因为在非叶子节点也存储数据，所以和数据的位置相关，最好为O[1],最差为O[logN]
B+树因为所有的数据都在叶子节点中存储，所以查询效率和位置无关[忽略覆盖索引]，都是O[logN]

另外还有一点，InnoDB是已数据页为单位来存储数据的，默认情况下数据页大小为16KB。

我们假设MySQL每次只加载一个数据页，因为B+数在非叶子节点中并不保存数据，那么可以肯定，一个数据页中包含的索引数量，B+树是远大于B树的。所以在同样的一次查询中，B树就可能造成更多的IO。

另外B+数的同层节点都是以一个链表的形式相连的，所以从一个数据页跳转到相邻的另一个数据页这个操作是十分高效的。

### 总结

- 因为是关系型数据库，会经常有范围查询的需求，所以排除了Hash结构
- 因为数据是存储在磁盘上的，而磁盘和内存的操作响应时间差了好几个数量级，所以减少内存和磁盘之间的内存交互十分重要。
- B树和B+树，都能实现范围查询，并且都是多叉结构(能够有效减少树的高度)
- B树和B+树的主要区别就是
	- B树每个节点都会存储数据
	- B+树只会在叶子节点存储数据
- 同样的大小一个数据页，B+树只存索引，B树既存索引，又存数据
- 所以加载同样数量的数据页，B+树能够加载更多的索引，所以就能够较少更多的IO操作。
- 另外B+树每层的节点之间都是相连的，能够更方便的进行相邻数据的查询。


### 参考

[why use b+tree](https://medium.com/@mena.meseha/what-is-the-difference-between-mysql-innodb-b-tree-index-and-hash-index-ed8f2ce66d69)

[为什么MySQL使用B+树](https://draveness.me/whys-the-design-mysql-b-plus-tree/)

[MySQL数据库索引为什么选择使用B+树](https://developpaper.com/why-does-mysql-database-index-choose-to-use-b-tree/)

[B+树在磁盘存储中的应用](https://www.cnblogs.com/nullzx/p/8978177.html)

[B+树的几点总结](https://blog.csdn.net/love_u_u12138/article/details/50285655?spm=1001.2014.3001.5501)


## MySQL Server 和存储引擎之间的执行过程

简单说 MySQL基本模块有

- 数据库连接池

负责管理数据库连接	

- SQL解析器

解析SQL

- SQL优化器

优化SQL，生成执行计划，比如要使用哪个索引,调整查询条件的顺序等等

- 执行器

按照执行计划，调用存储引擎接口，查询数据

- 存储引擎

和操作系统交互，从磁盘或内存中查询数据


![](/img/sqlflow.png)


### Server层和存储引擎的交互

我们把存储引擎之前的所有模称为成为Server层

我们以下面这个SQL为例来分析一下

```SQL

SELECT * FROM t WHERE key1 > 70 AND common_field != 'a';

```

首先建立了连接，然后sql进行了解析，通过了优化器，优化器认为通过扫描二级索引idx_key1中key1值在(70, +∞)这个区间中的二级索引记录的成本更小。

- server层先让InnoDB去查在key1值在(70, +无穷)区间中的第一条记录。
- InnoDB通过二级索引idx_key1对应的B+树，从B+树根页面一层一层向下定位，快速找到(70, +无穷)区间的第一条二级索引记录，然后根据该二级索引记录进行回表操作，找到完整的聚簇索引记录，然后返回给server层。
- server层判断InnoDB返回的记录符不符合搜索条件key1 > 70 AND common_field != 'a'，如果不符合的话就跳过该记录，否则将其发送到客户端。
- 然后server层向InnoDB要下一条记录。
- InnoDB根据上一次找到的二级索引记录的next_record属性，获取到下一条二级索引记录，回表后将完整的聚簇索引记录返回给server层。
- server继续判断，不符合搜索条件即跳过该记录，否则发送到客户端。
- 一直循环上述过程，直到InnoDB找不到下一条记录，则向server层报告查询完毕。
- server层收到InnoDB报告的查询完毕请求，停止查询。

下面我们看一下源码中的调用栈


![](/img/mysqlinvoke.awebp)

其中的`handler::ha_index_next`便是server层向存储引擎要下一条记录的接口。

其中的`row_search_mvcc`是读取一条记录最重要的函数，这个函数长的吓人，有一千多行：

![](/img/invokemvcc.awebp)

每读取一条记录，都要做非常多的工作，诸如进行多版本的可见性判断，要不要对记录进行加锁的判断，要是加锁的话加什么锁的选择，完成记录从InnoDB的存储格式到server层存储格式的转换等等等等十分繁杂的工作。


### 参考

[MySQL的COUNT语句是怎么执行的](https://juejin.cn/post/7021068351023611917)

[MySQL 优化器原来是这样工作的](https://zhuanlan.zhihu.com/p/192707721)

[MySQL一条SQL的执行过程详解](https://www.pdai.tech/md/db/sql-mysql/sql-mysql-execute.html)

## MySQL limit的问题和优化方案

在使用MySQL进行分页查询的时候，我们经常会使用到`limit`关键字。
但是`limit`在大数据量情况下会有很大的性能问题。

比如
```sql
## 取100w后的10条
select * from table where xxx limit 100000,10;
```
这个SQL在mysql的中的执行情况是，<span style="color: red;">mysql会根据查询条件，查出前100w条，然后丢弃，然后再取后面的10条数据。</span>

这样效率就有点低了，为了10条数据，却要查出来100w条数据，然后丢弃。


### 优化

对于这种情况优化的方式就是，尽量查出那10条记录的id，然后通过等值查询，去直接查询那10条记录。

```sql

select t.* from table t,
	(select id from table where xxx  limit 1000000,10) as b  
where t.id = b.id;

```

虽然在查询中，还是需要抛弃掉前100w条记录，但是这里因为我们只查询了id，所以这100w条并不需要回表了，通过二级索引就能获取，然后后面通过查询出来的10个主键，再去回表查询那10条记录。



### 参考

[MySQL的LIMIT这么差劲的吗](https://juejin.cn/post/7018170284687491080)

## MySQL Redo Log




## 如何向MySQL中插入大量数据

拼接大SQL 和 小SQL的对比

### 参考

[10万条数据批量插入，到底怎么做才快？](https://juejin.cn/post/7025876113943445518?utm_source=gold_browser_extension)


## MySQL字符集引起的全表扫描



## MySQL in 查询优化

我们知道使用 in查询是可以使用到索引的，但是在使用的时候也会有一些需要注意的。

MySQL在执行SQL的时候，会使用优化器对SQL进行优化，然后可以通过分析选取最优的索引进行查询。

但是如何进行分析也是一个问题，进行分析也不能占用太多的性能，所以就需要在性能和准确性之间进行一个权衡。

MySQL在执行等值范围查询例如select … from xxx where xxx in(…) 时，优化器在计算执行计划成本时会根据条件个数采用不同的方式以减小选择执行计划的开销。

- 当条件数N小于eq_range_index_dive_limit时，优化器认为此时条件个数尚可，可以采用成本较高但更为精确的index dive方式来计算执行成本。
- 当N大于或等于eq_range_index_dive_limit时，优化器会认为此时使用index dive的方式计算成本带来的开销过大，此时MySQL优化器会根据index statistics直接估算成本。

当使用 index_dive方式来计算执行成本的时候，会得到比较精确的结果，可以理解为直接使用索引查询了一次。

而使用 index statistics方式来计算成本，就不会太精确了，它会利用索引的一些统计信息进行估算。具体如何进行估算我们就不去深究了，但我们需要知道一个属性 `Cardinality` ,也就是索引的基数，也就是分离度。

### 线上SQL优化

```sql
select count(1) countGift FROM tbl_crm_customer_giftDetail WHERE cardTransID in ( 7043637759180801121 , 7043639146564289633 , 7043641237710050401 , 7043642135240770657 , 7043642457363317857 , 7043643621416899681 , 7043644197269668961 , 7043655755202823265 , 7043659629154272353 , 7043716932213679201 , 7043724834836067425 , 7043726673593771105 , 7043732690624848993 , 7043735078794437729 , 7043738948400587873 , 7043744506298004577 , 7043748255292728417 , 7043751219331859553 , 7043752130032702561 , 7043753813097870433 , 7043763073609376865 , 7043770945722385505 , 7043771954922271841 )
  
```

发现线上的这个SQL出现了慢查询，但是查询字段其实是有索引的。

线上使用的MySQL版本为5.6，其中`eq_range_index_dive_limit`的默认值为10。因为这里查询条件超过10，所以会使用基于 index statistics的方式估算成本，又因为该表字段比较多，平均一个数据页就能存储20条数据左右，所以计算出来索引的
`Cardinality` 也为20左右，(但是实际上该字段基本没有重复的)。所以导致执行计划认为该索引的区分度不高，从而改为需要扫描全部的索引记录。

#### 优化方案
将`eq_range_index_dive_limit`调整为200。修改只有，慢查询消失。

因为实际上这个字段的区分度很高，直接使用索引能搞得到很好的效果。




## MySQL中的一些限制

针对版本 5.7

- 单表列限制
	限制1000列左右
- 单表索引数量限制
	64个索引
- 单个联合索引使用字段数
	16个

### 参考

[InnoDB表的限制](https://zhuanlan.zhihu.com/p/79987871)


